{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4441b8f-976e-4c31-afc0-5b0731cc896f",
   "metadata": {},
   "source": [
    "# Deep Learning Project \n",
    "## LE Thi Hoa - p2310380"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43603e54-49f4-44d8-aba0-8f399a61fcfc",
   "metadata": {},
   "source": [
    "## Part 1 : Perceptron Indicate the size of each tensor of the provided file perceptron_pytorch.py. Explain. \n",
    "In file perceptron_pytorch.py, we have the tensors: \n",
    "- “data_train” is the training data, which is a tensor containing training samples from the MNIST dataset. The size of “data_train” is (number of training samples, number of features).\n",
    "- The size of tensor data_train = torch.Size([63000, 784])\n",
    "- “label_train” is the corresponding label for the training data. The size of “label_train” is (number of training samples, number of classes). \n",
    "- The size of tensor label_train = torch.Size([63000, 10])\n",
    "- “data_test” is the testing data, containing test samples from the MNIST dataset. The size of “data_test” is (number of testing samples, number of features).\n",
    "- The size of tensor data_test = torch.Size([7000, 784])\n",
    "- “Label_test” is the corresponding label for the testing data. The size of “label_test” is (number of testing samples, number of classes).\n",
    "- The size of tensor label_test = torch.Size([7000, 10])\n",
    "- “w” is a tensor that contains the model's weights. The size of “w” is (the number of features, the number of classes). It is initialized with random values in the range from -0.001 to 0.001.\n",
    "- The size of tensor w = torch.Size([784, 10])\n",
    "- “b” is a tensor that contains bias values of the model. The size of  “b” is (1, number of classes), and it is also initialized with random values in the range from -0.001 to 0.001.\n",
    "- The size of tensor b = torch.Size([1, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c426749-7bd2-43ab-a443-8295686dfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import torch, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "31ee7eac-bcc9-47fc-87f2-c2698519dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data_train torch.Size([63000, 784])\n",
      "Size of lable_train torch.Size([63000, 10])\n",
      "Size of data_test torch.Size([7000, 784])\n",
      "Size of label_test torch.Size([7000, 10])\n"
     ]
    }
   ],
   "source": [
    "# read data and check size \n",
    "\n",
    "((data_train, label_train), (data_test, label_test)) = torch.load(gzip.open(\"mnist.pkl.gz\"))\n",
    "\n",
    "print(\"Size of data_train\", data_train.shape)\n",
    "print(\"Size of lable_train\", label_train.shape)\n",
    "print(\"Size of data_test\", data_test.shape)\n",
    "print(\"Size of label_test\", label_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca79a5-2b26-434d-b85a-57b2acaa44b1",
   "metadata": {},
   "source": [
    "### Visualization images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e239b5bf-d244-47cd-9358-7932ae3778a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, figsize=(2, 2)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(figsize))\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f927153-764d-4f8b-90df-e4a4a91d52fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEcklEQVR4nO3dzWtcVRzH4ZtpA9YiNbZKxUINVC0ICqJiFBeCXVik4CIbi8VFsItYChYUX0BwIVR3unIh6MaArYK4EYsbK76gVERdWURc2VRQ24jVpBn/gHOCE9M7M9/J8yx/XDqn4ZMD587cyVi32+02EKYz6AXA/yFcIgmXSMIlknCJJFwiCZdIwiWScIm0sdcL93Sm21wHNE3TNCeWj/V0nR2XSMIlknCJJFwiCZdIwiWScIkkXCIJl0jCJZJwiSRcIgmXSMIlknCJJFwiCZdIwiWScIkkXCIJl0g9P+XLpfHL4bur86+efLWV1/vwr83F7JVdu1t5rX6y4xJJuEQSLpGESySHsyGx3Cy38u9e7I7m3jSa/ytGnnCJJFwiCZdIwiWScIkkXCIJl0jCJZJwieQt3xbNP15+9vboodcHsJLRY8clknCJJFwiCZdIwiWSuwot+ntLObtv00Irr3V8YXt1/sbMvmLWab5uZQ39ZMclknCJJFwiCZdIDmeXwPxs/WuVZve/37c1nF26ojrvnMw/iNXYcYkkXCIJl0jCJZJwieSuwiqdOVTeQThw8IPqtTNbfmx7OeuWHZdIwiWScIkkXCI5nK3SuZsuFrNDEz9Ur23nq5qbZu78dcXsrZceqF470XzW0ioGy45LJOESSbhEEi6RhEskdxVW8OvBqep8+p7Bn9JPLewsZhNvDn5d/WTHJZJwiSRcIgmXSA5nK/ht6p/q/IVrvqxM/f73m584kYRLJOESSbhEEi6R3FVomub3A+Xbu3tvPlW9tlP5XR8f21C9drG7tnW9s7CtOv/o3TuK2Y7m07W9WBg7LpGESyThEkm4RFpXh7M/9t9VnU8dLt/GPbq9/vnW2pO7Kx3Cltf4nO/bZ26vzne8uL4OYjV2XCIJl0jCJZJwiSRcIq2ruwobH5mvzle6g9BP7/1Zvr37/cld1Wuvb862vZyhZ8clknCJJFwiCZdII3s4u/DgncXstm2D/7u2tUNY0zTNc8cfLmaTzw7+0Dis7LhEEi6RhEsk4RJJuEQa2bsKVz9V/h3dl68d/Aewn/9mX3U++Yw7CKthxyWScIkkXCIJl0jxh7Pu1K3V+c7Lv+3zSkqfXLismC3+vHkAKxk9dlwiCZdIwiWScIkkXCJF3VXo3LK7mN372ufVa49s/a7t5fynmY8fLWY3Hqmvl9Wx4xJJuEQSLpGES6Sow9neufIzq49debqvazi9uFTMflqaqF47dm687eWsW3ZcIgmXSMIlknCJJFwiDeVdhQ1br6rOx8cG/4XGD809Ucwmn64/oXtD4+3dtthxiSRcIgmXSMIl0lAezma/qH9V0v2bzvd5JQwrOy6RhEsk4RJJuEQSLpHGut1ut5cL93Sm214LNCeWj/V0nR2XSMIlknCJJFwiCZdIwiWScIkkXCIJl0jCJZJwiSRcIgmXSMIlknCJJFwiCZdIwiWScIkkXCIJl0g9P+ULw8SOSyThEkm4RBIukYRLJOESSbhEEi6RhEukfwFuz4qsO9dEUQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAGrUlEQVR4nO3dbWiVdRzG8f85W05NV2nOMg2ftma2IM1SQynDF2pK4iSDTEfNCA0lDAkCRUhQCCm1Igsr7UkzyuxBTcyenJprVqNSSdOK5ZrVXGu67Zxe9Cp/v1P3PJvu2r6fl5c/z/kzr/3xvu9z7juWTCaTARATP98LAM4GxYUkigtJFBeSKC4kUVxIoriQRHEhieJCUmbUwbHxqS25DiCEEMK2xIZIc+y4kERxIYniQhLFhSSKC0kUF5IoLiRRXEiiuJBEcSGJ4kISxYUkigtJFBeSKC4kRf48LpoulpVls4yMtF83UXfKCRvTfl0l7LiQRHEhieJCEsWFJIoLSZxVaKJ4164m+2lWgTu7YNZrJpvWpTLtNQxaO9tk/R/Z684mGxrSfr/WiB0XkiguJFFcSKK4kMTBWQghlun8GAqucmcLX95uspnZO5t7Sf/pm+mrTDburSJ3NrZrf0sv57xgx4UkigtJFBeSKC4kUVxI4qxCCOHYQzeY7Ms5KyP//Zqk88HuEMKSyhEm27x+pDtb27feZGUTnnBnu8TsB9TbG3ZcSKK4kERxIYniQlK7OjjL6Jnj5nPvfjPya+w7bb9Ne9erD7qz/R7eZbLe4bPI7zVj5+1uvnHgeyY7NK2TO5tXag/kkqf8g0kl7LiQRHEhieJCEsWFJIoLSe3qrELsws5ufk/2jyb7uM7/0SybdKfJ+pXbswfNoWJ1P/8PltroYOGT7uiE56fb8IvyNFbVOrDjQhLFhSSKC0kUF5La1cFZorLKzXM/uNdkOVs7uLMXlZc065pwdthxIYniQhLFhSSKC0kUF5La11mFkyfdPHdG6TleSTQnJ/vrBTsuRFFcSKK4kERxIanNHpxlDLY3Zv6rT7Y7+8Nt9vc3f/Axf/bEJSbLWe1/zrdz2VGTNVT84s5630Auzv/UnfWUnfafrhOvtd/obQtP/WXHhSSKC0kUF5IoLiRRXEjSOqsQzzBRTeEwd3TBoy+abELnmmZfUgghhOF+PP7bSSZLLLrOnf35Rnvvrwcufj/yEgq3zHHzvO/2RH4NJey4kERxIYniQhLFhSSpg7PY0KtN9tFy/9ZDnupEnZsXH7EHUan06vSHyZZfvtudfTd/k8kOrPXXkBFLOql/s2ZP7gv6N2tuCnZcSKK4kERxIYniQhLFhSSpswpVC6MfOXvP1x29Yr4722tZ9Ec4Hcq2H0Yf+Nh97uwrtz5tsmFZHSO/VypFR282WWb5YXe2LXxo3MOOC0kUF5IoLiRRXEiSOjjbO2S9yRq9K6UhhMP19neyKQdhqTRWV5ssr3ivO7t4x0STvZ23Oe01fFI6yGS51f5l57aKHReSKC4kUVxIoriQRHEhSeqsQmuQ0aOHyarXdnVn1/a33zQOwb/PWFP031Cf9muoY8eFJIoLSRQXkiguJEkdnA3YXmSyA2Oec2cHdbC/kwfWDHVns8uyTNZ1XIU7O3/AVpNN7GwvA/8j/QMxz7H77U2c+37YIm+V0vHZI02WSNGmyx5P/1L7mdhxIYniQhLFhSSKC0kUF5JiyWQyxUex/21sfGpLr+V/ZfbpbbJNJfb+XK1FifOl5KI9M93ZZ4atM9mojv4joI431trXnex/0zi5rzz1As80/FoTHZ7nj5aPWmOyeIi5s+OvGBJ5CdsSGyLNseNCEsWFJIoLSRQXkqQOzkLM/ue/Yt4Id7R0/soWWcKUQ+NM9tXRXu7slevsU4I6bPncnW241V6OXrjav5x9U1bCZKme5XvH63NNFu/zpzu7ecRTJhuQGf3m0tcv8Z/8k7Mq+iVfDs7QplFcSKK4kERxIYniQpLWWQWPc6YhhBAyBvYzWeWonu7siQL7I8hfdsSdTfz2u83q/EdApauq2D9jsnvRqhZ5P8/iXwvc/J2Vo03W/dkS/0WiVSyEwFkFtHEUF5IoLiRRXEiS+pavK8V//BsPfm+ybk4WQgjdnMy/gHpuXVpW4+a3fD3FZDuu2Rj5dZdW2RtDhxDCGyvGmKzHS/vd2e61uyK/X0tgx4UkigtJFBeSKC4kUVxI0r/k2x7F7QfUYxc04QRRwv8nT9afPtsVNRsu+aJNo7iQRHEhieJCkv4l3/Yo0Wii5CmbtWXsuJBEcSGJ4kISxYUkigtJFBeSKC4kUVxIoriQRHEhieJCEsWFJIoLSRQXkiguJFFcSKK4kERxIYniQhLFhSSKC0kUF5IoLiRRXEiiuJBEcSGJ4kJS5Bs7A60JOy4kUVxIoriQRHEhieJCEsWFJIoLSRQXkiguJP0NB2M6ScJjz2wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFM0lEQVR4nO3dX2iVdRzH8d85Z+oaS3RuYGww9WzO1C4a+a+7wNm60Kg1+iNehDm1SNhIqAZeeBPoVLoNrxTUGJogWTGULiKTiQuihJDanDhquilMcnl2ni666/udnOOeQ3583q/LL1/kuXjzg9+z4zmpKIqiAIhJ/98PADwMwoUkwoUkwoUkwoUkwoUkwoUkwoUkwoWkskIXW9LtpXwOIIQQQl++t6A9TlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIIlxIKviLnfGvzNONZnZ1S7W7+8pLF8zs4xo7CyGEZ092mlljZ7//EPmpBzxhMnDiQhLhQhLhQhLhQhKXs2lkGha7882nz5vZG5Wj7m7PWJOZPX/xHXd3oO2QmT33V5e7u+RD/4KXJJy4kES4kES4kES4kES4kMRbhRBCurzczK732FkIIbRUXDOzpmMfuLvZ3fb2Xxd+dnebD9k/+X731n539+3Pt5tZNOD/u48rTlxIIlxIIlxIIlxI4nIWQrixo9nMvmne5+5u7N5tZtkjM/8TbOOxu2aWeS3l7o6unmtm1QMzfgQpnLiQRLiQRLiQRLiQRLiQlKi3CmWL6935RzuPm1nn8CZ3d14MbxA8Uf9PZtbx26vu7vjyyMz8/2f8+OLEhSTChSTChSTChaREXc4mFy1w5+2Vt8ys+6ul7m5D+CHWZ8LD4cSFJMKFJMKFJMKFJMKFpES9VRhqnVPw7rJPR9x5Lq6H+Y/0ymVm9m7tSXd317fbSvQUOjhxIYlwIYlwIYlwISlRl7OpJ/IF7/5dO9+dp38fmtEz3OxY586Pd/eY2Scjre5u9rD9GqhSXRofVZy4kES4kES4kES4kES4kJSotwr1X07zG7htdnR/z213teL9BjMbb/b/j+2dtgkzu7D2oLt7I2e/J+zP1+e5u7nhYXeeJJy4kES4kES4kES4kJSoy9nsPv/bjxu+7jCzq62fubsT5ybNrCI1292dlcqY2VTkfyZ4Y+97ZpYd4jd7p8OJC0mEC0mEC0mEC0mEC0mJeqsQ8v6ffJduvWRmm+pfdnf/aKkzsyev+x/jjrpGzezcilPu7lPfF/4hd3DiQhThQhLhQhLhQlKyLmdFyA35n3ldcNjOMyua3N0zzkVs781n3N2KLy4W8XTgxIUkwoUkwoUkwoUkwoUk3irEYOQF/2eoPEd/XOPOG8PluB4nEThxIYlwIYlwIYlwIYnLWQzy68f9eYjMrPb0rFI/TiJw4kIS4UIS4UIS4UIS4UISbxViUF15152P5++ZGR8YjwcnLiQRLiQRLiQRLiRxOStSpqbGzE40nXB3D9xaW+rHSSxOXEgiXEgiXEgiXEgiXEjirUKRxl7MmtncdLm7e2ZwpZktDFdif6Yk4sSFJMKFJMKFJMKFJC5nRaq6PGZmE5H9fV+UFicuJBEuJBEuJBEuJBEuJPFWoUhTv/xqZquOdrm75zfvN7Pt9W+6u9P9PBV8nLiQRLiQRLiQRLiQlIqiyH77sKMl3V7qZ5GVKvPvuPfO1plZVbn/dU2TW+xnepN4YevL9xa0x4kLSYQLSYQLSYQLSYQLSfzJNwZRLufO52wYNDP/nQKKxYkLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSQV/kBx4lHDiQhLhQhLhQhLhQhLhQhLhQhLhQhLhQhLhQtI/zIjE6E3Y4acAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    imshow(np.array(data_train[i], dtype='float').reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ca7ffde6-289d-4d65-bf7e-917bbd211961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tplt.subplot(330 + 1 + i)\n",
    "\t# plot raw pixel data\n",
    "\tplt.imshow(np.array(data_train[i], dtype='float').reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba5f30-af8b-4388-bccf-eeafd1b771b6",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d6f859ec-446e-49dd-af0f-b8424419e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5  # number of data read each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3810ff4d-288b-44e1-9a0a-3e0c5fc6f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the data loaders\n",
    "train_dataset = torch.utils.data.TensorDataset(data_train, label_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(data_test, label_test)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee79546-a6c9-4729-9816-58f89d27c18b",
   "metadata": {},
   "source": [
    "# Part 2: Shallow network\n",
    "- In this part, you will implement a MLP with only one hidden layer and a linear output layer.\n",
    "- By taking inspiration from perceptron_pytorch_data_auto_layer_optim.py, implement a shallow network using the tools provided by PyTorch.\n",
    "- Find some hyperparameters (η and the number of neurons in the hidden layer) that provide a good performance. Explain precisely your methodology and the influence of each hyperparameter on the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "357c593a-2439-4a90-875a-c7016b02a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple MLP model\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(self.relu(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac461afd-ceed-4716-a922-b5e817585d0c",
   "metadata": {},
   "source": [
    "#### Create a function to train model simpleMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1c3d73da-3e05-43f1-8fd9-4d3d6851f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_SimpleMLP(learning_rate, hidden_size):\n",
    "    \n",
    "    # Define\n",
    "    input_size = data_train.shape[1]  # Number of input features (corresponding to MNIST image size)\n",
    "    output_size = label_train.shape[1]  # Size of output (corresponding to digits 0 to 9)\n",
    "\n",
    "    # Define model simpleMLP\n",
    "    model = SimpleMLP(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(5):  # number of iteration (epoch)\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                output = model(data)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                _, labels = torch.max(target, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch: {epoch} - Accurary: {accuracy}\")\n",
    "            \n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100d9ea-18ea-489b-8157-f65750f39b39",
   "metadata": {},
   "source": [
    "#### Try different values to find best learning_rate and best hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "514f5994-5f16-4c1b-bc80-692bb073ff39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate 0.001 and hidden size 64\n",
      "Epoch: 0 - Accurary: 85.92857142857143\n",
      "Epoch: 1 - Accurary: 85.87142857142857\n",
      "Epoch: 2 - Accurary: 85.52857142857142\n",
      "Epoch: 3 - Accurary: 85.47142857142858\n",
      "Epoch: 4 - Accurary: 85.95714285714286\n",
      "Training with learning rate 0.001 and hidden size 128\n",
      "Epoch: 0 - Accurary: 86.44285714285714\n",
      "Epoch: 1 - Accurary: 85.02857142857142\n",
      "Epoch: 2 - Accurary: 85.67142857142858\n",
      "Epoch: 3 - Accurary: 85.2\n",
      "Epoch: 4 - Accurary: 86.35714285714286\n",
      "Training with learning rate 0.001 and hidden size 256\n",
      "Epoch: 0 - Accurary: 85.47142857142858\n",
      "Epoch: 1 - Accurary: 84.7\n",
      "Epoch: 2 - Accurary: 84.91428571428571\n",
      "Epoch: 3 - Accurary: 86.14285714285714\n",
      "Epoch: 4 - Accurary: 85.9\n",
      "Training with learning rate 0.01 and hidden size 64\n",
      "Epoch: 0 - Accurary: 82.34285714285714\n",
      "Epoch: 1 - Accurary: 79.38571428571429\n",
      "Epoch: 2 - Accurary: 80.37142857142857\n",
      "Epoch: 3 - Accurary: 82.22857142857143\n",
      "Epoch: 4 - Accurary: 81.78571428571429\n",
      "Training with learning rate 0.01 and hidden size 128\n",
      "Epoch: 0 - Accurary: 84.2\n",
      "Epoch: 1 - Accurary: 83.75714285714285\n",
      "Epoch: 2 - Accurary: 76.98571428571428\n",
      "Epoch: 3 - Accurary: 83.5\n",
      "Epoch: 4 - Accurary: 82.27142857142857\n",
      "Training with learning rate 0.01 and hidden size 256\n",
      "Epoch: 0 - Accurary: 81.87142857142857\n",
      "Epoch: 1 - Accurary: 83.81428571428572\n",
      "Epoch: 2 - Accurary: 82.48571428571428\n",
      "Epoch: 3 - Accurary: 81.45714285714286\n",
      "Epoch: 4 - Accurary: 83.8\n",
      "Training with learning rate 0.1 and hidden size 64\n",
      "Epoch: 0 - Accurary: 9.785714285714286\n",
      "Epoch: 1 - Accurary: 9.785714285714286\n",
      "Epoch: 2 - Accurary: 9.785714285714286\n",
      "Epoch: 3 - Accurary: 9.785714285714286\n",
      "Epoch: 4 - Accurary: 9.785714285714286\n",
      "Training with learning rate 0.1 and hidden size 128\n",
      "Epoch: 0 - Accurary: 9.785714285714286\n",
      "Epoch: 1 - Accurary: 9.785714285714286\n",
      "Epoch: 2 - Accurary: 9.785714285714286\n",
      "Epoch: 3 - Accurary: 9.785714285714286\n",
      "Epoch: 4 - Accurary: 9.785714285714286\n",
      "Training with learning rate 0.1 and hidden size 256\n",
      "Epoch: 0 - Accurary: 9.785714285714286\n",
      "Epoch: 1 - Accurary: 9.785714285714286\n",
      "Epoch: 2 - Accurary: 9.785714285714286\n",
      "Epoch: 3 - Accurary: 9.785714285714286\n",
      "Epoch: 4 - Accurary: 9.785714285714286\n",
      "Best Hidden Size: 128, Best Learning Rate: 0.001, Best Accuracy: 86.36%\n"
     ]
    }
   ],
   "source": [
    "# A few values of learning_rate and hidden_size\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "hidden_sizes = [64, 128, 256]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_hidden_size = 0\n",
    "best_learning_rate = 0.0\n",
    "\n",
    "# train model to find best hyperparameters\n",
    "for lr in learning_rates:\n",
    "    for hs in hidden_sizes:\n",
    "        print(f\"Training with learning rate {lr} and hidden size {hs}\")\n",
    "        acc = train_model_SimpleMLP(lr, hs)\n",
    "        \n",
    "        # Check if this combination is the best so far\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_hidden_size = hs\n",
    "            best_learning_rate = lr\n",
    "    \n",
    "print(f\"Best Hidden Size: {best_hidden_size}, Best Learning Rate: {best_learning_rate}, Best Accuracy: {best_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14c407-af7d-4acd-85a0-cb0325ac33b2",
   "metadata": {},
   "source": [
    "### Train model with hidden size = 128, Learning rate = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "39cd1d9a-2c97-4942-949e-9a1af6f4a44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Accurary: tensor([85.9571])\n",
      "Epoch: 1 - Accurary: tensor([85.2143])\n",
      "Epoch: 2 - Accurary: tensor([86.8000])\n",
      "Epoch: 3 - Accurary: tensor([85.1857])\n",
      "Epoch: 4 - Accurary: tensor([85.2857])\n"
     ]
    }
   ],
   "source": [
    "# Define model simpleMLP\n",
    "model_simpleMlP = SimpleMLP(data_train.shape[1], 128, label_train.shape[1])\n",
    "    \n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.SGD(model_simpleMlP.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):  # number of iteration (epoch)\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model_simpleMlP(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Evaluate the model on the test set\n",
    "    # testing the model (test accuracy is computed during training for monitoring)\n",
    "    acc = 0.0\n",
    "    # reading all the testing data\n",
    "    for x, t in test_loader:\t\n",
    "        # computing the output of the model\n",
    "        y = model_simpleMlP(x)\n",
    "        # checking if the output is correct\n",
    "        acc += torch.argmax(y,1) == torch.argmax(t,1)\n",
    "        \n",
    "    # printing the accuracy\n",
    "    print(f\"Epoch: {epoch} - Accurary: {(acc/data_test.shape[0])*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770ca37-87ae-4a28-b09c-6919f4b30fec",
   "metadata": {},
   "source": [
    "### Report: \n",
    "- The model is built as a simple feedforward neural network with: an input layer, a hidden layer, and an output layer.\n",
    "- Below are the details of how the model is constructed.\n",
    "- I use the ReLU activation function.\n",
    "- Hidden_size: Controls the model's capacity to capture complex patterns. A larger hidden_size can lead to better performance but may result in overfitting if not tuned properly.\n",
    "- Learning_rate: Determines the training speed and stability. The choice of learning rate affects the convergence and optimization process. Selecting an appropriate learning rate is necessary for successful training.\n",
    "- So,  I try different values of learning_rate and hidden_size to find the best hidden_size and learning_rate.\n",
    "- The code for the results: Best Hidden Size: **256**, Best Learning Rate: **0.001**, Best Accuracy: **86.35%%**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a4887-f6bc-4ebe-9ef8-afa2e0d92c29",
   "metadata": {},
   "source": [
    "# Part 3 : Deep network\n",
    "- As you are now more familar with PyTorch, you can use it to test deeper models.\n",
    "- Implement a deep network (i.e. with at least two hidden layers) using the tools\n",
    "provided by PyTorch.\n",
    "- Find some hyperparameters (η, number of hidden layers and the number of\n",
    "neurons in the hidden layers) that provide a good performance. \n",
    "- Explain precisely your methodology and the influence of each hyperparameter on the per- formance.\n",
    "\n",
    "#### Define a deeper model MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fe190173-4f59-47d2-97f5-f66804ff4637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define deeper model MLP\n",
    "class Deeper_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Deeper_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(data_train.shape[1], 512)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, label_train.shape[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc16bd6-d135-4712-8ca4-ae68e69934c8",
   "metadata": {},
   "source": [
    "#### Creater a function to train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b9370acc-ae8c-4fd4-88bf-435cbe04a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training deeper model MLP\n",
    "def train_deeper_mlp(learning_rate):\n",
    "    model_deeper = Deeper_MLP()\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    optimizer = optim.SGD(model_deeper.parameters(), lr=learning_rate)\n",
    "\n",
    "    # iteration (epoch)\n",
    "    for epoch in range(5):  \n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model_deeper(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                output = model_deeper(data)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                _, labels = torch.max(target, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch: {epoch} - Accurary: {accuracy}\")\n",
    "            \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f1fcf-181e-427b-baff-ae1a380a55c0",
   "metadata": {},
   "source": [
    "#### Try difference values of learning_rates and hidden_size to find best values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "512a0501-582c-4c4e-a4cd-1f303a7a9fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate 0.001\n",
      "Epoch: 0 - Accurary: 94.84285714285714\n",
      "Epoch: 1 - Accurary: 96.54285714285714\n",
      "Epoch: 2 - Accurary: 97.27142857142857\n",
      "Epoch: 3 - Accurary: 97.64285714285714\n",
      "Epoch: 4 - Accurary: 98.05714285714286\n",
      "Training with learning rate 0.01\n",
      "Epoch: 0 - Accurary: 97.55714285714286\n",
      "Epoch: 1 - Accurary: 98.08571428571429\n",
      "Epoch: 2 - Accurary: 98.42857142857143\n",
      "Epoch: 3 - Accurary: 98.41428571428571\n",
      "Epoch: 4 - Accurary: 98.64285714285714\n",
      "Training with learning rate 0.1\n",
      "Epoch: 0 - Accurary: 10.085714285714285\n",
      "Epoch: 1 - Accurary: 10.842857142857143\n",
      "Epoch: 2 - Accurary: 10.085714285714285\n",
      "Epoch: 3 - Accurary: 10.042857142857143\n",
      "Epoch: 4 - Accurary: 10.942857142857143\n",
      "Best Learning Rate: 0.01, Best Accuracy: 98.64%\n"
     ]
    }
   ],
   "source": [
    "# The values of learning_rate and hidden_size\n",
    "learning_rates_deeper = [0.001, 0.01, 0.1]\n",
    "\n",
    "best_accuracy_deeper = 0.0\n",
    "best_learning_rate_deeper= 0.0\n",
    "\n",
    "\n",
    "# find best values\n",
    "for lr in learning_rates:\n",
    "    print(f\"Training with learning rate {lr}\")\n",
    "    acc = train_deeper_mlp(lr)\n",
    "        \n",
    "    # Check if this combination is the best so far\n",
    "    if acc > best_accuracy_deeper:\n",
    "        best_accuracy_deeper = acc\n",
    "        best_learning_rate_deeper = lr\n",
    "    \n",
    "print(f\"Best Learning Rate: {best_learning_rate_deeper}, Best Accuracy: {best_accuracy_deeper:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02835ec-ae3b-4b7e-91fa-3089c63e7020",
   "metadata": {},
   "source": [
    "### Explanations\n",
    "- Model Deeper_MLP - It is a multi-layer perceptron (MLP) model with three fully connected layers.\n",
    "- The layers in the model are defined as follows:\n",
    "\n",
    "- fc1: Input layer with data_train.shape[1] input features and 512 output features.\n",
    "- relu: ReLU activation function.\n",
    "- fc2: Hidden layer with 512 input features and 256 output features.\n",
    "- fc3: Output layer with 256 input features and label_train.shape[1] output features.\n",
    "- The forward method is responsible for the forward pass of the model. It takes an input x, reshapes it to a 2D tensor, and passes it through the layers in the defined sequence, applying ReLU activation after each fully connected layer. The final output of the model is returned.\n",
    "- I use ReLU activation function\n",
    "- Similar to part 2, I try several learning_rate values to find the best value.\n",
    "- Best Learning Rate: **0.01**, Best Accuracy: **98.64%**\n",
    "- Improve the model by finding the best value of **number of hidden layers** and **the number of\n",
    "neurons in the hidden layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce6c89-cd55-4f05-9557-55e8279702a9",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------- \n",
    "### Find some hyperparameters (η, number of hidden layers and the number of neurons in the hidden layers) that provide a good performance. \n",
    "## ------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b1790a63-30d5-4bf8-9bc9-023411c8137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model with at least two hidden layers\n",
    "class DeepNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(DeepNetwork, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i + 1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b4ca3bfe-0c0f-42a7-9342-23058473eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and test a model with a specific set of parameters\n",
    "def train_and_evaluate(learning_rate, hidden_sizes):\n",
    "    # Model definition\n",
    "    model_deeper = DeepNetwork(input_size, hidden_sizes, output_size)\n",
    "\n",
    "    # Loss function definition and optimization\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    optimizer = optim.SGD(model_deeper.parameters(), lr=learning_rate)\n",
    "\n",
    "    # iteration (epoch)\n",
    "    for epoch in range(5):  \n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model_deeper(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                output = model_deeper(data)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                _, labels = torch.max(target, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch: {epoch} - Accurary: {accuracy}\")\n",
    "            \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057daa6c-6985-4145-a570-6fe1b16c426e",
   "metadata": {},
   "source": [
    "- Designing a function to train and evaluate a deep neural network model with a specific set of hyperparameters, including learning rate and hidden layer sizes.\n",
    "- It performs training using the Adam optimizer and means squared error loss for a specified number of epochs. After each epoch, it evaluates the model on the test set and prints the accuracy.\n",
    "- The purpose is to observe the model's performance under different hyperparameter configurations and assess how changes in learning rate and hidden layer sizes affect accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d452578-8091-49ef-a9ca-f79b78edde54",
   "metadata": {},
   "source": [
    "### Try with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3e9815e0-6500-4cd3-b3aa-f80bf3276907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Accurary: 93.45714285714286\n",
      "Epoch: 1 - Accurary: 94.98571428571428\n",
      "Epoch: 2 - Accurary: 95.87142857142857\n",
      "Epoch: 3 - Accurary: 96.15714285714286\n",
      "Epoch: 4 - Accurary: 96.38571428571429\n",
      "Learning Rate: 0.001, Hidden Sizes: [64, 32], Accuracy: 96.38571428571429\n",
      "Epoch: 0 - Accurary: 94.04285714285714\n",
      "Epoch: 1 - Accurary: 95.91428571428571\n",
      "Epoch: 2 - Accurary: 96.58571428571429\n",
      "Epoch: 3 - Accurary: 96.95714285714286\n",
      "Epoch: 4 - Accurary: 97.3\n",
      "Learning Rate: 0.001, Hidden Sizes: [128, 64], Accuracy: 97.3\n",
      "Epoch: 0 - Accurary: 94.47142857142858\n",
      "Epoch: 1 - Accurary: 96.04285714285714\n",
      "Epoch: 2 - Accurary: 96.8\n",
      "Epoch: 3 - Accurary: 97.4\n",
      "Epoch: 4 - Accurary: 97.58571428571429\n",
      "Learning Rate: 0.001, Hidden Sizes: [256, 128], Accuracy: 97.58571428571429\n",
      "Epoch: 0 - Accurary: 96.18571428571428\n",
      "Epoch: 1 - Accurary: 96.91428571428571\n",
      "Epoch: 2 - Accurary: 97.38571428571429\n",
      "Epoch: 3 - Accurary: 97.31428571428572\n",
      "Epoch: 4 - Accurary: 97.31428571428572\n",
      "Learning Rate: 0.01, Hidden Sizes: [64, 32], Accuracy: 97.31428571428572\n",
      "Epoch: 0 - Accurary: 96.5\n",
      "Epoch: 1 - Accurary: 97.54285714285714\n",
      "Epoch: 2 - Accurary: 97.92857142857143\n",
      "Epoch: 3 - Accurary: 97.97142857142858\n",
      "Epoch: 4 - Accurary: 98.12857142857143\n",
      "Learning Rate: 0.01, Hidden Sizes: [128, 64], Accuracy: 98.12857142857143\n",
      "Epoch: 0 - Accurary: 97.55714285714286\n",
      "Epoch: 1 - Accurary: 98.01428571428572\n",
      "Epoch: 2 - Accurary: 98.44285714285714\n",
      "Epoch: 3 - Accurary: 98.38571428571429\n",
      "Epoch: 4 - Accurary: 98.48571428571428\n",
      "Learning Rate: 0.01, Hidden Sizes: [256, 128], Accuracy: 98.48571428571428\n",
      "Best Parameters: Learning Rate = 0.01, Hidden Sizes = [256, 128], Best Accuracy = 98.48571428571428\n"
     ]
    }
   ],
   "source": [
    "# The values to try \n",
    "learning_rates = [0.001, 0.01]\n",
    "hidden_sizes_list = [[64, 32], [128, 64], [256, 128]]\n",
    "\n",
    "# Generate all parameter combinations\n",
    "parameter_combinations = [(lr, hs) for lr in learning_rates for hs in hidden_sizes_list]\n",
    "\n",
    "# Set up hyperparameters\n",
    "input_size = 784  \n",
    "output_size = 10  \n",
    "num_epochs = 5\n",
    "\n",
    "# Start searching for hyperparameters\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for lr, hs in parameter_combinations:\n",
    "    accuracy = train_and_evaluate(lr, hs)\n",
    "    print(f'Learning Rate: {lr}, Hidden Sizes: {hs}, Accuracy: {accuracy}')\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = (lr, hs)\n",
    "\n",
    "print(f'Best Parameters: Learning Rate = {best_params[0]}, Hidden Sizes = {best_params[1]}, Best Accuracy = {best_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df36ecd-59b3-49fa-8a68-b0a6a6405e35",
   "metadata": {},
   "source": [
    "#### Best Parameters: \n",
    "- Learning Rate = 0.01: The learning rate is a hyperparameter that determines the step size at each iteration while moving toward a minimum of the loss function. In this case, a learning rate of 0.001 was found to be the most effective during the model training process.\n",
    "- Hidden Sizes = [256, 128]: The hidden sizes refer to the number of neurons in each hidden layer of the neural network. In this context, the model has two hidden layers with 256 neurons in the first hidden layer and 128 neurons in the second hidden layer. These values were identified as optimal for achieving the highest accuracy during training.\n",
    "- Best Accuracy = 98.48571428571428%: This represents the highest accuracy achieved by the model on the test set. It indicates the percentage of correctly predicted instances out of the total instances in the test set. The mentioned accuracy of approximately 97.94% is considered the best accuracy attained by the model under the specified learning rate and hidden layer sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a9ec0-2cf4-47a2-bc42-aee2f7800165",
   "metadata": {},
   "source": [
    "### Try With 3 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1a2a97f6-4119-45d1-b18e-8c1ca8dcb376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Accurary: 92.11428571428571\n",
      "Epoch: 1 - Accurary: 94.94285714285714\n",
      "Epoch: 2 - Accurary: 96.15714285714286\n",
      "Epoch: 3 - Accurary: 96.44285714285714\n",
      "Epoch: 4 - Accurary: 96.81428571428572\n",
      "Learning Rate: 0.001, Hidden Sizes: [64, 32, 16], Accuracy: 96.81428571428572\n",
      "Epoch: 0 - Accurary: 93.42857142857143\n",
      "Epoch: 1 - Accurary: 95.51428571428572\n",
      "Epoch: 2 - Accurary: 96.37142857142857\n",
      "Epoch: 3 - Accurary: 96.94285714285714\n",
      "Epoch: 4 - Accurary: 97.32857142857142\n",
      "Learning Rate: 0.001, Hidden Sizes: [128, 64, 32], Accuracy: 97.32857142857142\n",
      "Epoch: 0 - Accurary: 94.34285714285714\n",
      "Epoch: 1 - Accurary: 96.05714285714286\n",
      "Epoch: 2 - Accurary: 96.88571428571429\n",
      "Epoch: 3 - Accurary: 97.41428571428571\n",
      "Epoch: 4 - Accurary: 97.8\n",
      "Learning Rate: 0.001, Hidden Sizes: [256, 128, 64], Accuracy: 97.8\n",
      "Epoch: 0 - Accurary: 94.44285714285714\n",
      "Epoch: 1 - Accurary: 96.94285714285714\n",
      "Epoch: 2 - Accurary: 96.7\n",
      "Epoch: 3 - Accurary: 97.35714285714286\n",
      "Epoch: 4 - Accurary: 97.07142857142857\n",
      "Learning Rate: 0.01, Hidden Sizes: [64, 32, 16], Accuracy: 97.07142857142857\n",
      "Epoch: 0 - Accurary: 96.45714285714286\n",
      "Epoch: 1 - Accurary: 97.57142857142857\n",
      "Epoch: 2 - Accurary: 97.88571428571429\n",
      "Epoch: 3 - Accurary: 97.47142857142858\n",
      "Epoch: 4 - Accurary: 98.01428571428572\n",
      "Learning Rate: 0.01, Hidden Sizes: [128, 64, 32], Accuracy: 98.01428571428572\n",
      "Epoch: 0 - Accurary: 97.47142857142858\n",
      "Epoch: 1 - Accurary: 97.71428571428571\n",
      "Epoch: 2 - Accurary: 98.0\n",
      "Epoch: 3 - Accurary: 98.05714285714286\n",
      "Epoch: 4 - Accurary: 98.08571428571429\n",
      "Learning Rate: 0.01, Hidden Sizes: [256, 128, 64], Accuracy: 98.08571428571429\n"
     ]
    }
   ],
   "source": [
    "# The values to try \n",
    "learning_rates = [0.001, 0.01]\n",
    "hidden_sizes_list_3_layer = [[64, 32, 16], [128, 64, 32], [256, 128, 64]]\n",
    "\n",
    "# Generate all parameter combinations\n",
    "parameter_combinations_3 = [(lr, hs) for lr in learning_rates for hs in hidden_sizes_list_3_layer]\n",
    "\n",
    "# Start searching for hyperparameters\n",
    "best_accuracy_3 = 0\n",
    "best_params_3 = None\n",
    "\n",
    "for lr, hs in parameter_combinations_3:\n",
    "    accuracy = train_and_evaluate(lr, hs)\n",
    "    print(f'Learning Rate: {lr}, Hidden Sizes: {hs}, Accuracy: {accuracy}')\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy_3 = accuracy\n",
    "        best_params_3 = (lr, hs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606fdcd0-4740-48da-929f-3e714267dd0a",
   "metadata": {},
   "source": [
    "#### Best Parameters:\n",
    "- Learning Rate = 0.001: The learning rate is a hyperparameter that controls the step size during the optimization process. In this case, a learning rate of 0.001 was found to be the most effective for updating the model parameters while training.\n",
    "- Hidden Sizes = [256, 128, 64]: The hidden sizes correspond to the number of neurons in each hidden layer of the neural network. The model in question has three hidden layers, with 256 neurons in the first layer, 128 neurons in the second layer, and 64 neurons in the third layer. These specific hidden layer sizes were determined as optimal for achieving high accuracy during training.\n",
    "- Best Accuracy = 97.98571428571428%: This indicates the highest accuracy achieved by the model on the test set. The accuracy represents the percentage of correctly predicted instances out of the total instances in the test set. In this scenario, the model achieved an accuracy of approximately 97.99%, which is considered the best accuracy under the specified learning rate and hidden layer sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a475bd1-326c-4f80-898f-78ce26383b83",
   "metadata": {},
   "source": [
    "### Let's discuss the hyperparameters and their influence:\n",
    "- **Learning Rate (learning_rate)**: This parameter controls the step size during optimization. Too high a learning rate may cause the model to converge too quickly and potentially overshoot the minimum. Too low a learning rate may result in slow convergence or the model getting stuck in a local minimum. Common values to try are 0.1, 0.01, 0.001, etc.\n",
    "- **Number of Hidden Layers (hidden_sizes)**: This parameter determines the depth of your network. Adding more layers allows the model to capture more complex relationships in the data but also increases the risk of overfitting. Start with a small number of hidden layers and gradually increase if needed.\n",
    "- **Number of Neurons in Hidden Layers (hidden_sizes)**: The number of neurons in each hidden layer influences the capacity of the model to learn complex patterns. More neurons provide the model with more capacity but also increase the risk of overfitting. You can experiment with different numbers based on the size of your dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eac1f5-ddcd-4654-9db0-cc73a6729875",
   "metadata": {},
   "source": [
    "## Part4:CNN\n",
    "- As you have now a deeper understanding of the MLP, it’s time to implement a CNN architecture (more adapted to images).\n",
    "- Implement a simple CNN using the tools provided by PyTorch (you can take inspiration from LeNet5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0b70e-53f6-437c-bc88-c85eba5a8cbd",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "- The layers in the model are defined as follows:\n",
    "- **conv1**: First convolutional layer with 1 input channel, 32 output channels, a kernel size of 3x3, and padding of 1\n",
    "- **conv2**: Second convolutional layer with 32 input channels, 64 output channels, a kernel size of 3x3, and padding of 1.\n",
    "- **relu**: ReLU activation function.\n",
    "- **pool**: Max pooling layer with a kernel size of 2x2 and stride of 2.\n",
    "- **fc1**: First fully connected (linear) layer with 64 * 7 * 7 input features and 128 output features.\n",
    "- **fc2**: Second fully connected layer with 128 input features and 64 output features.\n",
    "- **fc3**: Third fully connected layer with 64 input features and 32 output features.\n",
    "- **fc4**: Fourth fully connected layer with 32 input features and 10 output features (corresponding to the number of classes).\n",
    "- The forward method is responsible for the forward pass of the model. It takes an input x, passes it through the convolutional layers with ReLU activation and max pooling, reshapes it to a 1D tensor, and passes it through the fully connected layers. The final output of the model is returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b2d71043-6a35-4ae8-999f-4f6b07ccb6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SimpleCNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)  \n",
    "        self.fc4 = nn.Linear(32, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cfbe43d4-5c94-4123-8d17-609334d4fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Batch: 0, Loss: 6.314750671386719\n",
      "Epoch: 1/5, Batch: 2000, Loss: 0.2864203155040741\n",
      "Epoch: 1/5, Batch: 4000, Loss: 0.02600623108446598\n",
      "Epoch: 1/5, Batch: 6000, Loss: 0.019974127411842346\n",
      "Epoch: 1/5, Batch: 8000, Loss: 0.04266637563705444\n",
      "Epoch: 1/5, Batch: 10000, Loss: 0.03593865782022476\n",
      "Epoch: 1/5, Batch: 12000, Loss: 0.02863871119916439\n",
      "Epoch: 2/5, Batch: 0, Loss: 0.02428804710507393\n",
      "Epoch: 2/5, Batch: 2000, Loss: 0.018299585208296776\n",
      "Epoch: 2/5, Batch: 4000, Loss: 0.010704082436859608\n",
      "Epoch: 2/5, Batch: 6000, Loss: 0.005798154976218939\n",
      "Epoch: 2/5, Batch: 8000, Loss: 0.009090053848922253\n",
      "Epoch: 2/5, Batch: 10000, Loss: 1.0157384872436523\n",
      "Epoch: 2/5, Batch: 12000, Loss: 0.014176917262375355\n",
      "Epoch: 3/5, Batch: 0, Loss: 0.05187998712062836\n",
      "Epoch: 3/5, Batch: 2000, Loss: 0.015828900039196014\n",
      "Epoch: 3/5, Batch: 4000, Loss: 0.005755451042205095\n",
      "Epoch: 3/5, Batch: 6000, Loss: 0.011197309009730816\n",
      "Epoch: 3/5, Batch: 8000, Loss: 0.261119544506073\n",
      "Epoch: 3/5, Batch: 10000, Loss: 0.006582516245543957\n",
      "Epoch: 3/5, Batch: 12000, Loss: 0.015058256685733795\n",
      "Epoch: 4/5, Batch: 0, Loss: 0.0034383649472147226\n",
      "Epoch: 4/5, Batch: 2000, Loss: 0.002039045561105013\n",
      "Epoch: 4/5, Batch: 4000, Loss: 0.04026981443166733\n",
      "Epoch: 4/5, Batch: 6000, Loss: 0.0018242644146084785\n",
      "Epoch: 4/5, Batch: 8000, Loss: 0.046853579580783844\n",
      "Epoch: 4/5, Batch: 10000, Loss: 0.013133037835359573\n",
      "Epoch: 4/5, Batch: 12000, Loss: 0.00789361447095871\n",
      "Epoch: 5/5, Batch: 0, Loss: 0.011948775500059128\n",
      "Epoch: 5/5, Batch: 2000, Loss: 0.07023449242115021\n",
      "Epoch: 5/5, Batch: 4000, Loss: 0.002490636659786105\n",
      "Epoch: 5/5, Batch: 6000, Loss: 0.0032057377975434065\n",
      "Epoch: 5/5, Batch: 8000, Loss: 0.010665027424693108\n",
      "Epoch: 5/5, Batch: 10000, Loss: 0.010369130410254002\n",
      "Epoch: 5/5, Batch: 12000, Loss: 0.002539308276027441\n",
      "Training completed in 179.18106412887573 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, criterion, and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 5\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 2000 == 0:\n",
    "            print(f'Epoch: {epoch + 1}/{num_epochs}, Batch: {i}, Loss: {loss.item()}')\n",
    "\n",
    "print(f'Training completed in {time.time() - start_time} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9233d6ca-06fc-42b0-9abb-64bc29ce19eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bc1ba622-c4e7-434a-97cc-e5f81bef2136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.66%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ed4f3-0e2d-4670-930b-a14f37547240",
   "metadata": {},
   "source": [
    "## Part 5 : To push forward (optional)\n",
    "### If you have time and if you want, you can look at the following questions (non exhaustive list) :\n",
    "\n",
    "#### Try another loss fonction (as cross entropy) with Simple MLP (1 layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f87af8ca-0013-44b0-8880-15d7d62f1b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.33%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = SimpleMLP(data_train.shape[1], 128, label_train.shape[1])\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:  \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:  \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # If labels are one-hot encoded, convert them to class indices\n",
    "        _, true_labels = torch.max(labels, 1)\n",
    "        \n",
    "        total += true_labels.size(0)\n",
    "        correct += (predicted == true_labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d47bc-4c06-43ab-b358-2cfe245ea016",
   "metadata": {},
   "source": [
    "- With the same set of hyperparameters (hidden_size = 128, learning_rate = 0.001), when using Cross-Entropy, the model performs better than when using MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad98c17-6e8d-46b8-bcc9-fb132a0ecd5b",
   "metadata": {},
   "source": [
    "#### Try other activation functions as tanh with Simple MLP (1 layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b1ad14f6-1725-4fdb-b96b-0432bd7d3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with tanh activation: 100.50%\n"
     ]
    }
   ],
   "source": [
    "# Assume SimpleMLP is defined as follows\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.Tanh()  # Change activation function here\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model_tanh = SimpleMLP(data_train.shape[1], 128, label_train.shape[1])\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_tanh.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_tanh.train()\n",
    "    for inputs, labels in train_loader:  \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_tanh(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model_tanh.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:  \n",
    "        outputs = model_tanh(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_tanh = correct / total\n",
    "print(f'Test Accuracy with tanh activation: {accuracy_tanh * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8199371-8b83-45a5-9f3e-20bec8f5a2cc",
   "metadata": {},
   "source": [
    "#### Use a pretrained ResNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b694b64e-c428-4486-9d0b-f18026962e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2946af62-0fe6-4d11-8068-1a4f53d38fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_1 = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "346129ab-0fc4-4b8c-bdfd-b355031c9f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "resnet.fc = nn.Linear(2048, 10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9868ace-aa99-4cf0-aa93-31a3df471029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d833a-0014-42c5-bfb9-dc15aed03eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import models\n",
    "import time\n",
    "\n",
    "# Define the modified ResNet model for MNIST\n",
    "class ResNetMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetMNIST, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        # Modify the first convolutional layer to accept single-channel images\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Modify the fully connected layer to output 10 classes\n",
    "        resnet.fc = nn.Linear(512, 10)\n",
    "\n",
    "        # Use only the feature extraction part of ResNet\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "train_loader_res = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader_res = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model_res = ResNetMNIST()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_res.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 3\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_res.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader_res):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_res(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f'Training completed in {time.time() - start_time} seconds')\n",
    "\n",
    "# Evaluate the model\n",
    "model_res.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader_res:\n",
    "        outputs = model_res(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
